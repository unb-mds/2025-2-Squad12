# Projeto: **É Crypto**

## Visão Geral do Projeto

**É Crypto** é um portal dedicado a reunir, organizar e exibir notícias, informações e curiosidades sobre o universo das criptomoedas. O projeto utiliza técnicas de mineração de dados (web scraping) por meio de *spiders* especializadas, buscando conteúdo em múltiplas fontes confiáveis para garantir qualidade, diversidade e precisão das informações.

A proposta é entregar ao usuário uma plataforma intuitiva, moderna e de fácil navegação, tornando o complexo mundo das criptos acessível para todos — desde iniciantes até entusiastas.

---

## Resumo Rápido

* **Público-alvo:** Público geral, com ou sem conhecimento prévio em criptomoedas.
* **Escopo Inicial:** Coletar e exibir notícias e curiosidades iniciais sobre criptomoedas e validar a eficiência dos processos de mineração.

---

## Objetivos do Projeto

* Implementar **pipelines de mineração** que coletem dados de **vários sites confiáveis** (CoinDesk, CoinTelegraph, CryptoNews, etc.).
* **Normalizar, categorizar e armazenar** o conteúdo obtido (com metadados como título, texto limpo, data, autor, URL e categoria).
* Desenvolver uma **aplicação web completa** para que usuários explorem notícias e aprendam sobre cripto de forma simples.
* Criar um **sistema de votação/feedback**, permitindo que usuários avaliem as informações apresentadas.
* Garantir **reprodutibilidade** do pipeline com documentação, testes, scripts organizados e versionamento.

---

## Melhorias em Andamento

> Aqui listaremos todas as tarefas em progresso e funcionalidades planejadas:

* Desenvolvimento dos spiders iniciais usando Scrapy
* Definição da base de dados final (migração de CSV para banco relacional)
* Protótipo do frontend no Figma
* Sistema de avaliação de notícias com votos positivos/negativos
* Normalização automática do texto coletado
* Criação de API para comunicação entre backend e frontend

---

## Ferramentas Utilizadas

*(Itens podem ser atualizados conforme o projeto evolui.)*

* **Linguagens:** Python
* **Mineração / Scraping:** Scrapy
* **Processamento de Texto / NLP:** (a definir – ex.: spaCy ou NLTK)
* **Banco de Dados:** CSV (inicial), Banco relacional futuro (ex.: PostgreSQL/MySQL)
* **Backend / API:** Python (Flask ou FastAPI — ainda definir)
* **Frontend:** React (sugerido pelo grupo)
* **Versionamento:** Git & GitHub (issues, PRs, templates)
* **Outros serviços:** Figma, Trello/Notion (organização do time)

---

## Equipe do Projeto

| Nome                             | GitHub                                                                 |
| -------------------------------- | ---------------------------------------------------------------------- |
| Leonardo Rodrigues Martins       | [Antedeguemon21](https://github.com/Antedeguemon21) |
| Lucas Emanuel Costa dos Santos   | [TsukiRaiito](https://github.com/TsukiRaiito)       |
| João Paulo da Silva Pereira      | [??]                                           |
| Vitor Evangelista da Silva Alves | [SemC0ndicao](https://github.com/SemC0ndicao)       |
| Arthur Souto Santos              | [arthursouto09](https://github.com/arthursouto09)   |

---

## Links Importantes

* **Protótipo no Figma:** [Figma](https://www.figma.com/board/gPmz4LuhI7kQ9tcnGLQGlx/GRUPO-12---É-CRIPTO?node-id=0-1&p=f&t=3xEwZgVGTQQaDtm6-0)

---

## Como Contribuir

1. Faça um **fork** do repositório.
2. Crie uma branch com o padrão: `feature/nome-da-feature`.
3. Abra um **Pull Request**, descrevendo claramente as mudanças e testes realizados.
4. Atualize a seção **Melhorias em Andamento** com a tarefa relacionada à issue correspondente.

---

## Futuro: Pré-requisitos, Instalação e Guia de Uso

*(Esta seção será desenvolvida conforme o projeto evolui.)*

* Setup do ambiente Python
* Instalação de dependências (Scrapy, etc.)
* Como executar spiders
* Como rodar o backend
* Como iniciar o frontend
* Possíveis configurações avançadas

---


